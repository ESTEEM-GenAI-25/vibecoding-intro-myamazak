# ğŸ§­ Implementation & Ethics Memo
**Project:** RouteMark â€“ AI-Enhanced Engraved Travel Cards  
**Author:** Masafumi Yamazaki  
**Date:** December 2025  

---

## How I Actually Used AI While Building

When I started working on RouteMark, I didnâ€™t have a full technical plan. I had a mental image of a black aluminum card showing a curved line between two cities. I wanted it to look elegant, like something that could be physically engraved. To get there, I used AI mostly as a *thinking partner* rather than a black box that wrote the whole code for me.  

I worked mainly with **VS Code** and **Gemini**. I asked them to help me with HTML and JavaScript setup, the OpenLayers map functions, and the logic for drawing curved routes. The AI helped me quickly sketch out the structure, but the code it produced often needed manual fixing; coordinates were off and the map projection didnâ€™t behave the way I expected. I spent a lot of time iterating on the modification.

For the user interface, I used AI more like a design assistant. It gave me layout ideas for the sidebar, buttons, and the card preview area. However, most of the visual tuning (spacing, alignment, and how â€œengravedâ€ the map looked) came from my own experimentation. I realized AI was good at getting me to about 60% of the way there, but finishing the design always required human judgment.  
 

---

## Why the AI Feature in the Product Looks the Way It Does

Early in the project, I imagined a more ambitious AI feature. Maybe one that could automatically design the cardâ€™s layout or generate a photo-realistic engraving preview. But as I built more of the product, I realized that would distract from the real goal: creating a clean, believable memento of a journey.  

Thatâ€™s why I decided the AI feature should be *interpretive*, not generative. Instead of making images or random designs, it will eventually focus on **describing the route in a meaningful way**. For example, if someone chooses â€œTokyo â€“ New Yorkâ€ with a â€œPremiumâ€ vibe, AI could write a short note about the character of that journey or why the line appears bold and bright. Itâ€™s a way of adding emotional context to something geometric.  

This approach felt right for the kind of product I was making. RouteMark isnâ€™t about showing off AIâ€”itâ€™s about combining technology and craftsmanship. I wanted AI to support the storytelling side without taking over the visual identity of the product. The design should still feel like it could exist as a real, laser-engraved object, not just a digital experiment.  

I also kept the scope small on purpose. Generating complex visuals through AI image models could easily raise questions about originality or ownership. By keeping AIâ€™s role narrow â€” explaining style choices or recommending line aesthetics â€” the product stays more transparent and easier to trust.

---

## Risks, Trade-offs, and Integrity

I thought a lot about privacy, bias, and trust during development. Even though RouteMark doesnâ€™t collect personal data, it still takes user input that reflects real travel routes. I decided to keep everything client-side and avoid sending user data to external AI services until I can guarantee proper filtering. In the future, if I connect to an API like Gemini, Iâ€™ll make sure the route text is stripped down to just the city names before itâ€™s sent anywhere.  

Bias is another issue I had to think about. If AI writes descriptions like â€œTokyo â€“ New York represents ambition,â€ thatâ€™s still a subjective statement that can reflect cultural assumptions. I plan to handle that by constraining prompts so they focus on neutral tone and avoid stereotypes. AI should describe the *style* of the design, not the meaning of the cities or people involved.  

I also made sure that AI is not essential for the app to work. The main features â€” drawing the route, stitching the coastlines, showing the card preview, and adding to cart â€” all work independently. If the AI feature stops working, the app should still function. This helps prevent users from being forced to rely on AI where it isnâ€™t necessary.  

Finally, I want to be transparent about academic integrity. Every time I used AI, I edited the results, understood the logic, and rewrote large sections myself. The AI helped me learn new techniques faster, but it never replaced my own reasoning. In that sense, I see AI as a modern extension of open-source culture â€” it gives you pieces, but you still have to assemble them into something thatâ€™s yours.

---

## What I Learned About Building with GenAI

The biggest thing I learned from using AI was how much *direction* matters. When I gave vague prompts like â€œmake a modern UI,â€ the results were random and usually messy. When I explained why I wanted something â€” for example, â€œcreate a layout that looks precise enough for an engraving previewâ€ â€” the results were much closer to what I wanted. It taught me that writing good prompts isnâ€™t about length; itâ€™s about intent.  

Another lesson was that AI canâ€™t replace aesthetic decisions. Itâ€™s very good at producing functional solutions, but not taste. The difference between a technical map and a product that *feels right* came from me adjusting small visual details â€” line weight, shading, balance. Thatâ€™s something no model can predict yet.  

If another founder asked me for advice, Iâ€™d tell them to treat AI like a second pair of hands, not a second brain. Itâ€™s great for scaffolding and brainstorming, but it doesnâ€™t understand the emotional or practical goals behind your product. You have to define those first.  

This project also changed how I think about AI in my future work. I used to see AI mainly as a research or analysis tool. Now I see it as something that can bridge creativity and engineering. In future ventures, especially in materials and design applications, Iâ€™ll keep this mindset: use AI for structure, but always let the human side shape meaning and final quality.
